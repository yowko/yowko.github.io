<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fluentd on Yowko&#39;s Notes</title><link>https://blog.yowko.com/tags/fluentd/</link><description>Recent content in Fluentd on Yowko&#39;s Notes</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 04 May 2019 21:30:00 +0800</lastBuildDate><atom:link href="https://blog.yowko.com/tags/fluentd/index.xml" rel="self" type="application/rss+xml"/><item><title>Fluentd 使用自定 Log 時間當做 Timestamp</title><link>https://blog.yowko.com/fluentd-log-time/</link><pubDate>Sat, 04 May 2019 21:30:00 +0800</pubDate><guid>https://blog.yowko.com/fluentd-log-time/</guid><description>Fluentd 使用自定 Log 時間當做 Timestamp 之前筆記 Fluentd 安裝 Elasticsearch Output Plugin 封裝成 Docker image 提到最近需要 debug EFK 起因就是發現 Kibana 顯示儲存在 Elasticsearch 中的時間與過濾條件都是 log 的處理時間並非 log 真正的</description></item><item><title>Fluentd 安裝 Elasticsearch Output Plugin 封裝成 Docker image</title><link>https://blog.yowko.com/fluentd-elasticsearch-docker/</link><pubDate>Thu, 02 May 2019 21:30:00 +0800</pubDate><guid>https://blog.yowko.com/fluentd-elasticsearch-docker/</guid><description>Fluentd 安裝 Elasticsearch Output Plugin 封裝成 Docker image 近期專案的 log 集中化採用 EFK - Elasticsearch + Fluentd + Kibana (log parser 改用 Fluentd 而非 Logstash 主要是因為 Logstash 有 memory 使用量大的問題)，這幾天發現設定上有些問題導致資料</description></item></channel></rss>